{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your name:\n",
    "\n",
    "<pre> Your name here</pre>\n",
    "\n",
    "### Collaborators:\n",
    "\n",
    "<pre> Enter the name of the people you worked with if any</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(123)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification - Based on Week 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Build a classification model for the default of credit card clients dataset. More info here:\n",
    "https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients\n",
    "\n",
    "In week 3, you:\n",
    "- Explored the dataset\n",
    "- Built a full data pipeline\n",
    "- Pre-processed data, explored features\n",
    "\n",
    "Building on your work of week 3:\n",
    "- Split dataset into 3 sets:\n",
    "  - 70% -> Training and cross validation\n",
    "  - 15% -> Model Stacking\n",
    "  - 15% -> Testing\n",
    "  \n",
    "\n",
    "- Tune a decision tree classfier:\n",
    "  - select a score (http://scikit-learn.org/stable/modules/model_evaluation.html). Explain your choice \n",
    "  - tune one parameter a time. Generate a plot for the score vs parameter values. Analyze your results.\n",
    "    - criterion, max_depth, min_samples_split, min_samples_leaf, max_leaf_nodes=None    \n",
    "  - tune all parameters at the same time using a randomgrid(http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV). First, run with a coarse grid, then refine in the next iteration. Use the information from the previous step to select parameter values.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Your code here\n",
    "\n",
    "## Feel free to use multiple cells\n",
    "\n",
    "df = pd.read_excel(\"/path/to/file/default of credit card clients.xls\", \n",
    "                   sheet = 0, skiprows= 1, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Learning\n",
    "\n",
    "Make sure to read and understand the documentation for each classifier.\n",
    "\n",
    "Remember to make your code modular; it will save you rewriting the same things multiple times and will help avoid copy paste errors.\n",
    "\n",
    "\n",
    "  \n",
    "- Tune the following classifiers:\n",
    "  - Random forest classfier\n",
    "  - Adaboost Tree classifier\n",
    "  - Extra trees classifier\n",
    "  - Gradient Boosted Tree classifier\n",
    "  - Logistic Regression\n",
    "  \n",
    "- Analyze, compare, and interpret your results\n",
    "- What ensemble yields the best result? Can you identify certain types of events that are classified better/worse from the type of algorithm?\n",
    "- Is the feature importance consistent for all classifiers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Stack your models. \n",
    "  - Combine the models from the previous section using the stacking approach: \n",
    "    - Choose the model use to combine. Examples are:\n",
    "      - Linear Regression\n",
    "      - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain your results and choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. (Optional) If a Decision Tree is overfitting the training set, is it a good idea to try decreasing max_depth?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`answer here`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. (Optional) If a Decision Tree is underfitting the training set, is it a good idea to try scaling the input features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`answer here`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. (Optional) What is the difference between hard and soft voting classifiers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`answer here`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. (Optional) If your AdaBoost ensemble underfits the training data, what hyperparameters should you tweak and how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`answer here`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. (Optional) If your Gradient Boosting ensemble overfits the training set, should you increase or decrease the learning rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`answer here`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit your notebook\n",
    "\n",
    "Submit your solution here\n",
    "https://goo.gl/forms/VKD7Zwu54oHjutDc2\n",
    "Make sure you rename your notebook to    \n",
    "W3_UTORid.ipynb    \n",
    "Example W3_adfasd01.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
